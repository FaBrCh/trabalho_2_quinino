---
title: "Análise de Sobrevivência e Otimização de Manutenção para Transformadores"
format:
  html:
    toc: true
    toc-title: "Conteúdo"
    number-sections: true
    self-contained: true
    code-fold: true
    code-tools: true
  revealjs:
    slide-level: 2
    theme: sky
    self-contained: true
lang: pt
---

```{r setup, include=FALSE}
library(dplyr)
library(ggplot2)
library(survival)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, fig.align = 'center')
```

## 1\. Introdução

O objetivo deste trabalho é determinar uma política ótima de manutenção para um conjunto de transformadores de alta potência de uma empresa de energia elétrica. Após uma falha, os custos de reparo são elevados e a companhia pode ser multada por interrupções não programadas no fornecimento de energia [@fonteEmpresaAno]. Uma estratégia de manutenção preventiva bem definida é crucial para otimizar recursos e aumentar a confiabilidade do sistema elétrico [@normaSetorAno].

Nesta análise, consideramos dois tipos de intervenção:

  - **Reparo Mínimo (MR - *Minimal Repair*):** Realizado após uma falha. Restaura a função do equipamento, mas o retorna à condição de confiabilidade exata de antes da falha, ou seja, "tão ruim quanto antes" (*bad as old*) [@barlow1975; @brown1981].
  - **Manutenção Preventiva (PM - *Preventive Maintenance*):** Ação planejada e completa que retorna o sistema a um estado de "como novo" (*good as new*) [@nakagawa2007].

## 2\. Modelagem do Processo de Falhas

Para descrever as falhas que ocorrem entre as manutenções preventivas, utilizamos um modelo estatístico para sistemas reparáveis.

### Modelo Adotado: Processo de Poisson Não Homogêneo (NHPP)

O NHPP é ideal para modelar eventos (falhas) que ocorrem ao longo do tempo com uma taxa que não é constante [@rigdon2000]. A taxa de falhas, ou **função de intensidade**, é denotada por $\rho(t)$.

A forma específica utilizada é o **Power Law Process (PLP)**, que é a implementação mais popular do NHPP para análise de confiabilidade de sistemas reparáveis [@crow1991; @asher1984]. A função de intensidade do PLP é dada por:

$$
\rho(t) = \frac{\beta}{\theta}\left(\frac{t}{\theta}\right)^{\beta-1}
$$  - Os parâmetros $\beta$ (forma) e $\theta$ (escala) são análogos aos da distribuição de Weibull.
- **Significado de $\beta$**: Se $\beta \> 1$, a taxa de falhas aumenta com o tempo, indicando um processo de desgaste e justificando a necessidade de manutenção preventiva. Se $\beta \< 1$, a confiabilidade melhora com o tempo (mortalidade infantil). Se $\beta = 1$, as falhas são constantes (aleatórias), caracterizando um Processo de Poisson Homogêneo.

## 3\. Análise dos Dados

### 3.1. Estimação dos Parâmetros do Modelo

O primeiro passo é estimar os parâmetros $\beta$ e $\theta$ a partir dos dados históricos de falha dos transformadores. Utilizamos o **Método da Máxima Verossimilhança (MLE)**, que encontra os valores dos parâmetros que maximizam a probabilidade de observar os dados coletados.

```{r estimacao, eval=TRUE}
dados_trafo <- data.frame(
Equi = c(1, 1, 1, 2, 2, 2, 3, 3, 4, 5, 6, 7, 7, 8, 8, 9, 9, 10, 11, 12, 12, 12, 13, 14, 14, 14, 15, 16, 16, 17, 17, 18, 19, 20, 20, 20, 21, 22, 23, 23, 24, 24, 25, 26, 27, 27, 28, 28, 29, 30, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40),
Failure_Time = c(8839, 17057, 21887, 9280, 16442, 21887, 10445, 13533, 7902, 8414, 13331, 17156, 21887, 16305, 21887, 16802, 21887, 4881, 16625, 7396, 7541, 19590, 2211, 15821, 19746, 19877, 1927, 15813, 21886, 15524, 21886, 21440, 369, 11664, 17031, 21857, 7544, 6039, 2168, 6698, 18840, 21879, 2288, 2499, 10668, 16838, 15550, 21887, 1616, 14041, 20004, 21888, 21888, 21888, 21888, 21888, 21888, 21888, 21888, 21888, 21888),
Censura = c(1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)
)

dados_lista <- dados_trafo %>%
  group_by(Equi) %>%
  summarise(
    falhas = list(Failure_Time[Censura == 1]),
    tempo_final = max(Failure_Time)
  )

neg_log_likelihood_plp <- function(params, dados) {
  beta <- params[1]; theta <- params[2]
  if (beta <= 0 || theta <= 0) return(Inf)

  total_log_likelihood <- sum(sapply(1:nrow(dados), function(i) {
    tempos_falha <- unlist(dados$falhas[[i]])
    tempo_max <- dados$tempo_final[i]
    
    log_intensidade <- 0
    if (length(tempos_falha) > 0) {
      log_intensidade <- sum(dweibull(tempos_falha, shape = beta, scale = theta, log = TRUE) -
                               pweibull(tempos_falha, shape = beta, scale = theta, lower.tail = FALSE, log.p = TRUE))
    }
    intensidade_acumulada <- (tempo_max / theta)^beta
    
    log_likelihood_unit <- log_intensidade - intensidade_acumulada
    return(log_likelihood_unit)
  }))

  return(-total_log_likelihood)
}

valores_iniciais <- c(2.0, 20000)
otimizacao_corrigida <- optim(
  par = valores_iniciais, 
  fn = neg_log_likelihood_plp, 
  dados = dados_lista,
  method = "BFGS",
  control = list(parscale = valores_iniciais)
)
beta_estimado_correto <- otimizacao_corrigida$par[1]
theta_estimado_correto <- otimizacao_corrigida$par[2]
```

**Resultados da Estimação:**
```{r print_estimacao, echo=FALSE}
cat("Parâmetros do Modelo Power Law Process (PLP) Estimados via MLE (versão final.r):\n\n")
cat(paste0("  - **Beta (Forma):** ", round(beta_estimado_correto, 4), "\n"))
cat(paste0("  - **Theta (Escala):** ", round(theta_estimado_correto, 2), "\n"))
```
O valor de **$\beta \approx 1.995$** é significativamente maior que 1, o que confirma a hipótese de um processo de desgaste acelerado e reforça a necessidade de uma política de manutenção preventiva.

### 3.2. Avaliação da Adequação do Modelo

Para validar nosso modelo, comparamos a **Mean Cumulative Function (MCF)**, que representa a média de falhas acumuladas ao longo do tempo. Comparamos a curva não-paramétrica (calculada diretamente dos dados via estimador de Nelson-Aalen) com a curva paramétrica (prevista pelo nosso modelo PLP com os parâmetros estimados). Se as curvas forem próximas, o modelo é considerado adequado.

```{r mcf_plot}
dados_intervalo <- dados_trafo %>% group_by(Equi) %>%
  mutate(tempo_inicio = lag(Failure_Time, default=0), evento = Censura, tempo_fim = Failure_Time)
surv_obj <- Surv(time=dados_intervalo$tempo_inicio, time2=dados_intervalo$tempo_fim, event=dados_intervalo$evento)
fit_na <- survfit(surv_obj ~ 1)
mcf_na_data <- data.frame(tempo = fit_na$time, mcf = fit_na$cumhaz)

mcf_parametrica <- function(t, beta, theta) { (t / theta)^beta }

ggplot(mcf_na_data, aes(x = tempo, y = mcf)) +
  geom_step(aes(color = "Dados (Nelson-Aalen)"), size = 1.2) +
  stat_function(fun = mcf_parametrica, args = list(beta = beta_estimado_correto, theta = theta_estimado_correto),
                aes(color = "Modelo (Weibull)"), size = 1) +
  labs(title = "Avaliação do Modelo (Versão Corrigida)",
       subtitle = "Com os parâmetros corretos, o ajuste do modelo é excelente.",
       x = "Tempo (horas)", y = "Média de Falhas Acumuladas (MCF)", color = "Estimador") +
  scale_color_manual(values = c("Dados (Nelson-Aalen)" = "dodgerblue", "Modelo (Weibull)" = "red")) +
  theme_bw() +
  theme(legend.position = "bottom") +
  coord_cartesian(xlim = c(0, 22000))
```

A forte sobreposição entre as curvas no gráfico acima demonstra que o modelo PLP ajustado descreve o processo de falhas dos transformadores com excelente precisão.

## 4\. Determinação da Política Ótima de Manutenção

O objetivo final é encontrar o intervalo de manutenção preventiva, $\tau$, que minimiza o custo esperado por unidade de tempo, $H(\tau)$. A função de custo é definida como [@gilardoni2007]:

$$H(\tau) = \frac{C_{PM} + C_{MR} \cdot M(\tau)}{\tau}
$$Onde $M(\tau) = (\tau / \theta)^\beta$ é a MCF do nosso modelo e a razão de custos entre reparo mínimo e manutenção preventiva é definida como $C_{MR}/C_{PM} = 15$. Para o modelo PLP, a solução ótima $\tau^*$ que minimiza $H(\tau)$ pode ser encontrada analiticamente pela fórmula:

$$
\tau^* = \theta \left[ \frac{C_{PM}}{C_{MR}(\beta-1)} \right]^{1/\beta}
$$### Resultados da Otimização

Aplicando a fórmula com os parâmetros estimados, encontramos o intervalo ótimo e visualizamos a função de custo para confirmar o ponto de mínimo.

```{r custo_plot}
C_PM <- 1; C_MR <- 15
tau_otimo <- theta_estimado_correto * (C_PM / ((beta_estimado_correto - 1) * C_MR))^(1 / beta_estimado_correto)
funcao_custo_H <- function(tau, beta, theta, cpm, cmr) { (cpm + cmr * (tau / theta)^beta) / tau }
custo_otimo <- funcao_custo_H(tau_otimo, beta_estimado_correto, theta_estimado_correto, C_PM, C_MR)

intervalo_tau <- seq(tau_otimo - 800, tau_otimo + 800, length.out = 500)
dados_custo <- data.frame(tau = intervalo_tau, 
                          custo = funcao_custo_H(intervalo_tau, beta_estimado_correto, theta_estimado_correto, C_PM, C_MR))

ggplot(dados_custo, aes(x = tau, y = custo)) +
  geom_line(color = "blue", size = 1) +
  geom_vline(xintercept = tau_otimo, color = "red", linetype = "dashed", size = 1) +
  annotate("point", x = tau_otimo, y = custo_otimo, color = "red", size = 4) +
  annotate("text", 
           x = tau_otimo, 
           y = custo_otimo + (max(dados_custo$custo, na.rm = TRUE) - min(dados_custo$custo, na.rm = TRUE))*0.05, 
           label = paste0("Ponto Ótimo\nτ* ≈ ", round(tau_otimo), " horas\nH(τ*) ≈ ", format(custo_otimo, scientific = FALSE, digits = 5)),
           hjust = 0.5, vjust = 0, 
           size=3.5
           ) +
  labs(title = "Função de Custo da Manutenção Preventiva (Focado no Ótimo)",
       x = "Intervalo de Manutenção Preventiva τ (horas)",
       y = "Custo por Unidade de Tempo H(τ)") +
  theme_bw() +
  theme(panel.grid.major = element_line(linetype = 'dotted'),
        panel.grid.minor = element_line(linetype = 'dotted'))
```

**Política Ótima de Manutenção:**
```{r print_otimo, echo=FALSE}
cat(paste0("  - **Intervalo ótimo (τ*):** ", round(tau_otimo), " horas.\n"))
cat(paste0("  - **Equivalente a:** Aproximadamente ", round(tau_otimo/24), " dias.\n"))
```
## 5\. Conclusão

- O processo de falha dos transformadores é bem descrito por um modelo de **desgaste** (PLP com $\beta \> 1$), validando a necessidade de manutenção preventiva.
- A análise fornece uma **política de manutenção orientada por dados**: realizar uma manutenção preventiva completa a cada **\~6213 horas (ou \~259 dias)**.
- Adotar este intervalo ótimo permite à empresa minimizar os custos operacionais totais, equilibrando os gastos com manutenções planejadas e os custos mais elevados de reparos corretivos não planejados.

:::